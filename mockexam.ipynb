{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probeklausur \"Grundlagen des Maschinellen Lernens\"\n",
    "\n",
    "## Aufgabe 1: Grundlagen und Evaluation\n",
    "\n",
    "(a) \n",
    "\n",
    "numerische Messwerte zu Gewicht, Größe und Körpertemperatur - Feature Space $ X $\n",
    "\n",
    "Menge der zu unterscheidenden Tierarten - Classes $ C $\n",
    "\n",
    "fachkundige:r Zoolog:in, welche:r Tiere identifiziert - $ \\gamma(o) $\n",
    "\n",
    "Waage, Thermometer, Messstab - $ \\alpha(o) $\n",
    "\n",
    "(b1)\n",
    "\n",
    "3\n",
    "\n",
    "(b2)\n",
    "\n",
    "Für die Klassifikatoren $ y_i'(), i = 1, \\dots, 3 $ haben die Trainings- und Testmengen jeweils die folgenden Anzahlen an Beispielen:\n",
    "\n",
    "$ |D_{test}| = 2 $\n",
    "\n",
    "$ |D_{tr}| = |D| - |D_{test}| = 6 - 2 = 4 $\n",
    "\n",
    "(b3)\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{split}\n",
    "\\text{Err}^*(y(), D, k) & = \\frac{1}{k} \\sum\\limits_{i = 1}^{k} \\frac{|(\\mathbf{x}, c) \\in D_{test_i}: y_i'(\\mathbf{x}) \\neq c|}{|D_{test_i}|} \\\\\n",
    "& = \\frac{1}{3} \\cdot (\\frac{1}{2} + \\frac{1}{2} + \\frac{0}{2}) \\\\\n",
    "& = \\frac{1}{3}\n",
    "\\end{split}\n",
    "\\end{equation*}\n",
    "\n",
    "## Aufgabe 2: Concept Learning\n",
    "\n",
    "Schritt 1:\n",
    "\n",
    "Inkonsistente Hypothesen aus $ H_S $ entfernen:\n",
    "\n",
    "$ H_S = \\{(sunny, warm, normal, ?, warm, same)\\} $\n",
    "\n",
    "Schritt 2:\n",
    "\n",
    "Entfernen von inkonsistenten Hypothesen aus $ H_G $:\n",
    "\n",
    "$ H_G = \\{(sunny, warm, ?, ?, ?, same)\\} $\n",
    "\n",
    "Hinzufügen von minimalen Spezialisierungen von $ \\{(sunny, ?, normal, ?, ?, same)\\} $:\n",
    "\n",
    "$ \\{(sunny, warm, normal, ?, ?, same), (sunny, cold, normal, ?, ?, same), (sunny, ?, normal, strong, ?, same), $\n",
    "\n",
    "$ (sunny, ?, normal, weak, ?, same), (sunny, ?, normal, ?, warm, same), (sunny, ?, normal, ?, cold, same)\\} $\n",
    "\n",
    "Consistent with $ \\mathbf{x}_1 $:\n",
    "\n",
    "$ \\{(sunny, warm, normal, ?, ?, same), (sunny, ?, normal, strong, ?, same), (sunny, ?, normal, ?, warm, same)\\} $\n",
    "\n",
    "Those with a more specific counterpart in $ H_S $:\n",
    "\n",
    "$ H_G = \\{(sunny, warm, ?, ?, ?, same), (sunny, warm, normal, ?, ?, same), (sunny, ?, normal, ?, warm, same)\\} $\n",
    "\n",
    "Remove hypothesis from $ H_G $ with less general counterparts in $ H_G $:\n",
    "\n",
    "$ H_G = \\{(sunny, warm, ?, ?, ?, same), (sunny, ?, normal, ?, warm, same)\\} $\n",
    "\n",
    "## Aufgabe 3: Lineare Modelle\n",
    "\n",
    "(a1)\n",
    "\n",
    "$ \\displaystyle y(\\mathbf{x}) = \\sigma(\\mathbf{w}^T \\mathbf{x}) = \\frac{1}{1 + e^{-\\mathbf{w}^T \\mathbf{x}}} $\n",
    "\n",
    "(a2)\n",
    "\n",
    "In Zeile 7 wird die Ableitung der Loss-Funktion berechnet in Bezug zu $ \\mathbf{w} $ und mit der Lernrate multipliziert. Die skalierte Differenz wird anschließend in Zeile 8 verwendet, um $ \\mathbf{w} $ zu aktualisieren.\n",
    "\n",
    "(a3)\n",
    "\n",
    "In Zeile 6 und 7 wird die Ableitung der jeweiligen Loss-Funktion berechnet. Im Fall der linearen Regression ist es der squared loss $ l_2 $, im Fall der logistischen Regression wird der logistische Loss $ l_{\\sigma} $ verwendet.\n",
    "\n",
    "(b1)\n",
    "\n",
    "$ \\hat{y}(\\mathbf{x}) = \\text{sign}(\\mathbf{w}^T \\mathbf{x}) $\n",
    "\n",
    "(b2)\n",
    "\n",
    "Goodness of fit as RSS:\n",
    "\n",
    "$ \\displaystyle \\sum\\limits_{(\\mathbf{x}, c) \\in D} (c - y(\\mathbf{x}))^2 $\n",
    "\n",
    "### Aufgabe 4: Bayesian Learning\n",
    "\n",
    "(a)\n",
    "\n",
    "Das Bayes-Theorem stellt den Zusammenhang zwischen Prior-, Posterior und Likelihood-Wahrscheinlichkeiten.\n",
    "\n",
    "$ \\displaystyle P(A_i \\mid B) = \\frac{P(A_i) \\cdot P(B \\mid A_i)}{\\sum\\limits_{i = 1}^{k} P(A_i) \\cdot P(B \\mid A_i)} $"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d0620f40e2353b6d35268ab276de4393f4e99801270e1c452fb1fe73380c5b64"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

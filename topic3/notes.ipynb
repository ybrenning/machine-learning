{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Linear Models\n",
    "\n",
    "## Logistic Regression\n",
    "\n",
    "### Binary Classification Problems\n",
    "\n",
    "Setting:\n",
    "* $ X $ is a multiset of feature vectors from an inner product space $ \\mathbf{X}, \\mathbf{X} \\in \\mathbb{R} $\n",
    "* $ C = \\{0, 1\\} $ is a set of two classes\n",
    "* $ D = \\{(\\mathbf{x}_1, c_1), \\dots, (\\mathbf{x}_n, c_n)\\} \\subseteq X \\times C $ is a multiset of examples\n",
    "\n",
    "Learning task:\n",
    "* Fit $ D $ using a logistic function $ y() $.\n",
    "\n",
    "Examples for binary classification problems:\n",
    "* E-Mail is spam or ham?\n",
    "* Patient infected or healthy?\n",
    "* Customer creditworthy or not?\n",
    "\n",
    "### Linear Regression\n",
    "\n",
    "![img1](img/topic3img1.png)\n",
    "\n",
    "* Linear Regression: $ y(\\mathbf{x}) = \\mathbf{w}^T \\mathbf{x} $\n",
    "* Classification: Predict \"spam\" if $ y(\\mathbf{x}) \\geq 0 $ else \"ham\"\n",
    "\n",
    "Restrict the range of $ y(\\mathbf{x}) $ to reflect the two-class classification semantics:\n",
    "\n",
    "$ -1 \\leq y(\\mathbf{x}) \\leq 1 $ or $ 0 \\leq y(\\mathbf{x}) \\leq 1 $ \n",
    "\n",
    "### Sigmoid (Logistic) Function\n",
    "\n",
    "$ \\sigma(z) = \\frac{1}{1 + e^{-z}} $\n",
    "\n",
    "Linear Regression $ \\circ $ Sigmoid Function $ \\rightarrow $ Logistic Model Function\n",
    "\n",
    "$ \\mathbf{w}^T \\mathbf{x} \\circ \\frac{1}{1 + e^{-z}} \\rightarrow y(\\mathbf{x}) \\equiv \\sigma(\\mathbf{w}^T \\mathbf{x}) = \\frac{1}{1 + e^{\\mathbf{w}^T \\mathbf{x}}} $\n",
    "\n",
    "$ y: \\mathbb{R}^{p + 1} \\rightarrow (0; 1) $\n",
    "\n",
    "This is interpreted as the estimated probability for th event $ \\boldsymbol{\\mathsf{C}} = 1 $:\n",
    "* $ y(\\mathbf{x}) = P(\\boldsymbol{\\mathsf{C}}=1 \\mid \\boldsymbol{\\mathsf{X}}=\\mathbf{x}; \\mathbf{w}) =: p(1 \\mid \\mathbf{x}; \\mathbf{w}) $ \"Probability for C=1 given x, parameterized w\"\n",
    "* * $ 1- y(\\mathbf{x}) = P(\\boldsymbol{\\mathsf{C}}=0 \\mid \\boldsymbol{\\mathsf{X}}=\\mathbf{x}; \\mathbf{w}) =: p(0 \\mid \\mathbf{x}; \\mathbf{w}) $ \"Probability for C=0 given x, parameterized w\"\n",
    "\n",
    "Example (email spam classification):\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{split}\n",
    "\\mathbf{x} = \n",
    "\\begin{pmatrix}\n",
    "x_0 \\\\ \n",
    "x_1\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "1 \\\\ \n",
    "|\\text{obscene words}|\n",
    "\\end{pmatrix},\n",
    "\\mathbf{x}_1 = \n",
    "\\begin{pmatrix}\n",
    "1 \\\\\n",
    "5\n",
    "\\end{pmatrix}\n",
    "\\text{ and }\n",
    "y(\\mathbf{x}_1) = 0.67\n",
    "\\end{split}\n",
    "\\end{equation*}\n",
    "\n",
    "$ \\Rightarrow $ 67% chance that this email is spam.\n",
    "\n",
    "\n",
    "Recap: **Linear Regression for classification**\n",
    "![img2](img/topic3img2.png)\n",
    "\n",
    "Recap: **Logistic Regression for classification**\n",
    "![img2](img/topic3img3.png)\n",
    "\n",
    "### The BGD Algorithm\n",
    "\n",
    "Algorithm: Batch Gradient Descent\n",
    "\n",
    "Input: \n",
    "- $ D $ (multiset of examples $ (\\mathbf{x}, c) $ with $ x \\in \\mathbb{R}^p, c \\in \\{0, 1\\} $)\n",
    "- $ \\eta $ Learning rate, small positive constant\n",
    "\n",
    "Output:\n",
    "\n",
    "$ \\mathbf{w} $ weight vector from $ \\mathbb{R}^{p + 1} $ (= hypothesis)\n",
    "\n",
    "![img4](img/topic3img4.png)\n",
    "\n",
    "\n",
    "(Repeat until convergence):\n",
    "\n",
    "`FOREACH (x, c) in D DO:`\n",
    "- [Model Function evaluation]\n",
    "- [Calculation of residual]\n",
    "- [Calculation of derivative of the loss, accumulate for D]\n",
    "`ENDDO`\n",
    "- Parameter Vector update = one gradient step down\n",
    "\n",
    "![img5](img/topic3img5.png)\n",
    "\n",
    "More complex polynomials will entail more conplex decision boundaries (see lecture notes)\n",
    "\n",
    "...\n",
    "\n",
    "## Loss Computation in Detail\n",
    "\n",
    "2nd part of ML stack: \"Optimization Objective\"\n",
    "* Objective: Minimize Loss\n",
    "* Regularization: None\n",
    "* Loss: 0/1 loss, squared loss, logistic loss, cross-entropy loss, hinge loss\n",
    "\n",
    "* The pointwise loss $ l(c, y(\\mathbf{x})) $ quantifies the error introduced by some $ \\mathbf{x} $. The loss depends on the hypothesis $ y() $ and the true class $ c $ of $ \\mathbf{x} $.\n",
    "* For $ y(\\mathbf{x}) = \\mathbf{w}^T \\mathbf{x} $ we define the following pointwise loss functions\n",
    "  - 0/1 loss : $ l_{0/1}(c, y(\\mathbf{x})) = I_{\\neq}(c, \\text{sign}(y(\\mathbf{x}))) $ which is zero if $ c = \\text{sign}(y(\\mathbf{x})) $ and 1 otherwise\n",
    "  - Squared loss : $ l_2(c, y(\\mathbf{x})) = (c - y(\\mathbf{x}))^2 $\n",
    "\n",
    "![img6](img/topic3img6.png)\n",
    "\n",
    "* For $ y(\\mathbf{x}) = \\sigma(\\mathbf{w}^T \\mathbf{x}) = \\frac{1}{1 + e^{-\\mathbf{w}^T \\mathbf{x}}} $ we define the following pointwise loss functions:\n",
    "  - 0/1 loss : $ l_{0/1}(c, y(\\mathbf{x})) = I_{\\neq}(c, \\lfloor y(\\mathbf{x}) + 0.5 \\rfloor) $\n",
    "  - Logistic loss : $ l_{\\sigma}(c, y(\\mathbf{x})) = -log(y(\\mathbf{x})) $ if $ c = 1 $, $ -log(1 - y(\\mathbf{x})) $ if $ c = 0$\n",
    "\n",
    "![img7](img/topic3img7.png)\n",
    "\n",
    "## Overfitting and Regularization\n",
    "\n",
    "### Overfitting\n",
    "let $ D $ be a multiset of examples and let $ H $ be a hypothesis space. The hypothesis $ h_2 \\in H $ is considered to overfit $ D $ if an $ h_1 \\in H $ exists with the following properties:\n",
    "\n",
    "$ \\text{Err}(h_2, D) < \\text{Err}(h_1, D) $ and $ \\text{Err}^*(h_1) < \\text{Err}^*(h_2) $\n",
    "\n",
    "Where $ \\text{Err}^*(h) $ denotes the true misclassification rate of $ h $ and $ \\text{Err}(h, D) $ denotes the error of $ h $ on $ D $.\n",
    "\n",
    "Reasons for overfitting are often rooted in the example set $ D $:\n",
    "* $ D $ is noisy\n",
    "* $ D $ is biased\n",
    "* $ D $ is too small\n",
    "\n",
    "![img8](img/topic3img8.png)\n",
    "\n",
    "Let $ D_{test} $ be a set of test samples. If $ D = D_{tr} \\cup D_{test} $ is representative of the real-world population in $ X $, then the quadratic model function $ y(x) = w_0 + w_1 \\cdot x + w_2 \\cdot x^2 $ is the closest match. \n",
    "\n",
    "![img9](img/topic3img9.png)\n",
    "\n",
    "Moreover, let $ D_{tr} $ and $ D_{test} $ be training and test sets of $ D $, and $ \\text{Err}(h, D_{test}) $ be an estimate for $ \\text{Err}^*(D_{test}) $ (holdout estimation). The hypothesis $ h_2 $ is considered to overfit $ D $ if an $ h_1 \\in H $ exists with the following property:\n",
    "\n",
    "$ \\text{Err}(h_2, D_{tr}) < \\text{Err}(h_1, D_{tr}) $ and $ \\text{Err}(h_1, D_{test}) < \\text{Err}(h_2, D_{test}) $ \n",
    "\n",
    "In particular: $ \\text{Err}(h_2, D_{test}) >> \\text{Err}(h_1, D_{tr}) $\n",
    "\n",
    "### Mitigation strategies\n",
    "\n",
    "How to detect overfitting\n",
    "* Visual inspection (apply projection or embedding for dimensionalities $ p > 3 $)\n",
    "* Validation (Given a test set, the difference $ \\text{Err}(y(), D_{test}) - \\text{Err}(y(), D_{tr}) $ is too large)\n",
    "\n",
    "How to tackle overfitting\n",
    "* Increase quantity and/or quality of the training data $ D $\n",
    "* Early stopping of the optimization (training) process\n",
    "* Regularization (increase model bias by constraining the hypothesis space)\n",
    "  - Model function (consider functions of lower compelexity)\n",
    "  - Hypothesis $ \\mathbf{w} $: Bound the absolute values of the weights in w of a model function\n",
    "\n",
    "\n",
    "### Regularization\n",
    "\n",
    "### Bound the absolute values of the weights $ \\mathbf{w} $\n",
    "\n",
    "Principle: Add to the loss function (term) a regularization function (term), $ R(\\mathbf{w}) $:\n",
    "\n",
    "$ \\mathcal{L}(\\mathbf{w}) = L(\\mathbf{w}) + \\lambda \\cdot R(\\mathbf{w}) $,\n",
    "\n",
    "Where $ \\lambda \\geq 0 $ controls the impact of $ R(\\mathbf{w}), R(\\mathbf{w}) \\geq 0 $\n",
    "\n",
    "![img10](img/topic3img10.png)\n",
    "\n",
    "![img11](img/topic3img11.png)\n",
    "\n",
    "Observations:\n",
    "* Model complexity depends (also) on the magnitude of weights $ \\mathbf{w} $\n",
    "* Minimizing $ L(\\mathbf{w}) $ sets no bounds on the weights $ \\mathbf{w} $\n",
    "* Regularization is achieved with \"counterweight\" $ \\lambda \\cdot R(\\mathbf{w}) $ that grows with $ \\mathbf{w} $\n",
    "* Aside from $ \\lambda $ no additional hyperparameter is introduced\n",
    "\n",
    "### The Vector Norm as Regularization Function\n",
    "\n",
    "* Ridge Regression\n",
    "* Lasso Regression\n",
    "\n",
    "![img12](img/topic3img12.png)\n",
    "\n",
    "![img13](img/topic3img13.png)\n",
    "\n",
    "...\n",
    "\n",
    "### Regularized Linear Regression\n",
    "\n",
    "* Given $ \\mathbf{x} $, predict a real-valued output under a linear model function:\n",
    "\n",
    "$ y(\\mathbf{x}) = w_0 + \\sum\\limits_{j = 1}^{p} w_j \\cdot x_j $\n",
    "\n",
    "* Vector notation with $ x_0 = 1 $ and $ \\mathbf{w} = (w_0, w_1, \\dots, w_p)^T $:\n",
    "\n",
    "$ y(\\mathbf{x}) = \\mathbf{w}^T \\mathbf{x} $\n",
    "\n",
    "* Given $ \\mathbf{x}_1, \\dots, \\mathbf{x}_n $, assess goodness of fit of the objective function:\n",
    "\n",
    "$ \\mathcal{L}(\\mathbf{w}) = \\text{RSS}(\\mathbf{w}) + \\lambda \\cdot R_{||\\vec{\\mathbf{w}}||_2^2}(\\mathbf{w}) $\n",
    "\n",
    "$ = \\sum\\limits_{i = 1}^{n} (y_i - \\mathbf{w}^T \\mathbf{x}_i)^2 + \\lambda \\cdot \\vec{\\mathbf{w}}^T \\mathbf{w} $\n",
    "\n",
    "...\n",
    "\n",
    "## Gradient Descent\n",
    "\n",
    "In the machine learning stack, gradient descent is part of the \"Optimization approach\" category.\n",
    "\n",
    "It is a first-order iterative optimization algorithm for finding a local extremum of a differentiable function $ f $.\n",
    "\n",
    "In our algorithms, $ f $ is the global loss function $ L $, or some other objective function $ \\mathcal{L} $.\n",
    "\n",
    "* The gradient $ \\nabla f $ of a differentiable function of several variables is a vector whose compenents are partial derivatives of $ f $.\n",
    "* The gradient of a function is the direction of steepest ascent or descent.\n",
    "* Gradient *ascent* means stepping in the direction of the gradient.\n",
    "* Likewise, *descent* steps in the opposite direction of the gradient, meaning it will find the local minimum of the function.\n",
    "\n",
    "\n",
    "### Linear Regression + Squared Loss\n",
    "\n",
    "![img14](img/topic3img14.png)\n",
    "\n",
    "Update of weight vector $ \\mathbf{w} $:\n",
    "\n",
    "$ \\mathbf{w} = \\mathbf{w} + \\Delta \\mathbf{w} $,\n",
    "\n",
    "using the gradient of the loss function $ L_2(\\mathbf {w}) $ to get the steepest descent:\n",
    "\n",
    "$ \\Delta \\mathbf{w} = -\\eta \\cdot \\nabla L_2(\\mathbf{w}) $\n",
    "\n",
    "...\n",
    "\n",
    "### The BGD Algorithm\n",
    "\n",
    "Algorithm: Batch Gradient Descent\n",
    "\n",
    "Input: \n",
    "* $ D $ multiset of examples $ (\\mathbf{w}, c) $ with $ \\mathbf{x} \\in \\mathbb{R}^p, c \\in \\{-1, 1\\} $\n",
    "* $ \\eta $ learning rate, small positive constant\n",
    "\n",
    "Output:\n",
    "$ \\mathbf{w} $ Weight vector from $ \\mathbb{R}^{p + 1} $ (hypothesis)\n",
    "\n",
    "![img15](img/topic3img15.png)\n",
    "\n",
    "Repeat until convergence:\n",
    "`FOREACH (x, c) in D DO`\n",
    "* Model function evaluation\n",
    "* Calculation of residual\n",
    "* Calculation of derivate for loss, accumulate for $ D $\n",
    "`ENDDO`\n",
    "* Parameter vector update = one gradient step down\n",
    "\n",
    "The weight adaptation of the BGD algorithm computes in each iteration the global loss, i.e. the loss of *all* examples in $ D $ (\"batch gradient descent\").\n",
    "\n",
    "The (squared) loss with regard to a single example (also called pointwise loss):\n",
    "\n",
    "$ l_2(c, y(\\mathbf{x})) = \\frac{1}{2}(c - \\mathbf{w}^T \\mathbf{x})^2 $\n",
    "\n",
    "The respective weight adaptation computes canonically as follows:\n",
    "\n",
    "$ \\Delta \\mathbf{w} = \\eta \\cdot (c - \\mathbf{w}^T \\mathbf{x})^2 \\cdot \\mathbf{x} $\n",
    "\n",
    "###  The IGD Algorithm\n",
    "\n",
    "Algorithm: Incremental Gradient Descent\n",
    "\n",
    "Input + Output are the same as the BGD.\n",
    "\n",
    "![img16](img/topic3img16.png)\n",
    "\n",
    "Repeat until convergence:\n",
    "`FOREACH (x, c) in D DO:`\n",
    "* Model function evaluation\n",
    "* Calculation of residual\n",
    "* Calculation of derivative\n",
    "* Parameter vector update = one gradient step down\n",
    "`ENDDO`\n",
    "\n",
    "\n",
    "### Linear Regression + 0/1 Loss\n",
    "\n",
    "![img17](img/topic3img17.png)\n",
    "\n",
    "Since $ L_{0/1}(\\mathbf{w}) $ is not a differentiable function, the gradient descent method cannot be applied to determine its minimum.\n",
    "\n",
    "### Logistic Regression + Logistic Loss + Regularization\n",
    "\n",
    "![img18](img/topic3img18.png)\n",
    "\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d0620f40e2353b6d35268ab276de4393f4e99801270e1c452fb1fe73380c5b64"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
